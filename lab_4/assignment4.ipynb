{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow 2.x\n",
    "\n",
    "1) Подготовка данных\n",
    "\n",
    "2) Использование Keras Model API\n",
    "\n",
    "3) Использование Keras Sequential + Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для выполнения лабораторной работы необходимо установить tensorflow версии 2.0 или выше .\n",
    "\n",
    "Рекомендуется использовать возможности Colab'а по обучению моделей на GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 22:20:22.598221: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-04 22:20:22.683077: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-04 22:20:23.067152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-04 22:20:24.439873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных\n",
    "Загрузите набор данных из предыдущей лабораторной работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 0us/step\n",
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,) int32\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_cifar10(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Fetch the CIFAR-10 dataset from the web and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.\n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 dataset and use appropriate data types and shapes\n",
    "    cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10\n",
    "    X_train = np.asarray(X_train, dtype=np.float32)\n",
    "    y_train = np.asarray(y_train, dtype=np.int32).flatten()\n",
    "    X_test = np.asarray(X_test, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test, dtype=np.int32).flatten()\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean pixel and divide by std\n",
    "    mean_pixel = X_train.mean(axis=(0, 1, 2), keepdims=True)\n",
    "    std_pixel = X_train.std(axis=(0, 1, 2), keepdims=True)\n",
    "    X_train = (X_train - mean_pixel) / std_pixel\n",
    "    X_val = (X_val - mean_pixel) / std_pixel\n",
    "    X_test = (X_test - mean_pixel) / std_pixel\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "# If there are errors with SSL downloading involving self-signed certificates,\n",
    "# it may be that your Python version was recently installed on the current machine.\n",
    "# See: https://github.com/tensorflow/tensorflow/issues/10779\n",
    "# To fix, run the command: /Applications/Python\\ 3.7/Install\\ Certificates.command\n",
    "#   ...replacing paths as necessary.\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "NHW = (0, 1, 2)\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_cifar10()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape, y_train.dtype)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, X, y, batch_size, shuffle=False):\n",
    "        \"\"\"\n",
    "        Construct a Dataset object to iterate over data X and labels y\n",
    "        \n",
    "        Inputs:\n",
    "        - X: Numpy array of data, of any shape\n",
    "        - y: Numpy array of labels, of any shape but with y.shape[0] == X.shape[0]\n",
    "        - batch_size: Integer giving number of elements per minibatch\n",
    "        - shuffle: (optional) Boolean, whether to shuffle the data on each epoch\n",
    "        \"\"\"\n",
    "        assert X.shape[0] == y.shape[0], 'Got different numbers of data and labels'\n",
    "        self.X, self.y = X, y\n",
    "        self.batch_size, self.shuffle = batch_size, shuffle\n",
    "\n",
    "    def __iter__(self):\n",
    "        N, B = self.X.shape[0], self.batch_size\n",
    "        idxs = np.arange(N)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        return iter((self.X[i:i+B], self.y[i:i+B]) for i in range(0, N, B))\n",
    "\n",
    "\n",
    "train_dset = Dataset(X_train, y_train, batch_size=64, shuffle=True)\n",
    "val_dset = Dataset(X_val, y_val, batch_size=64, shuffle=False)\n",
    "test_dset = Dataset(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (64, 32, 32, 3) (64,)\n",
      "1 (64, 32, 32, 3) (64,)\n",
      "2 (64, 32, 32, 3) (64,)\n",
      "3 (64, 32, 32, 3) (64,)\n",
      "4 (64, 32, 32, 3) (64,)\n",
      "5 (64, 32, 32, 3) (64,)\n",
      "6 (64, 32, 32, 3) (64,)\n"
     ]
    }
   ],
   "source": [
    "# We can iterate through a dataset like this:\n",
    "for t, (x, y) in enumerate(train_dset):\n",
    "    print(t, x.shape, y.shape)\n",
    "    if t > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Keras Model Subclassing API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Для реализации собственной модели с помощью Keras Model Subclassing API необходимо выполнить следующие шаги:\n",
    "\n",
    "1) Определить новый класс, который является наследником tf.keras.Model.\n",
    "\n",
    "2) В методе __init__() определить все необходимые слои из модуля tf.keras.layer\n",
    "\n",
    "3) Реализовать прямой проход в методе call() на основе слоев, объявленных в __init__()\n",
    "\n",
    "Ниже приведен пример использования keras API для определения двухслойной полносвязной сети. \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = '/cpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "class TwoLayerFC(tf.keras.Model):\n",
    "    def __init__(self, hidden_size, num_classes):\n",
    "        super(TwoLayerFC, self).__init__()        \n",
    "        initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "        self.fc1 = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.fc2 = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                   kernel_initializer=initializer)\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "    \n",
    "    def call(self, x, training=False):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_TwoLayerFC():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = TwoLayerFC(hidden_size, num_classes)\n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_TwoLayerFC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте трехслойную CNN для вашей задачи классификации. \n",
    "\n",
    "Архитектура сети:\n",
    "    \n",
    "1. Сверточный слой (5 x 5 kernels, zero-padding = 'same')\n",
    "2. Функция активации ReLU \n",
    "3. Сверточный слой (3 x 3 kernels, zero-padding = 'same')\n",
    "4. Функция активации ReLU \n",
    "5. Полносвязный слой \n",
    "6. Функция активации Softmax \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Conv2D\n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(tf.keras.Model):\n",
    "    def __init__(self, channel_1, channel_2, num_classes):\n",
    "        super(ThreeLayerConvNet, self).__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Implement the __init__ method for a three-layer ConvNet. You   #\n",
    "        # should instantiate layer objects to be used in the forward pass.     #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(channel_1, (5, 5), padding='same', activation='relu')\n",
    "        self.conv2 = tf.keras.layers.Conv2D(channel_2, (3, 3), padding='same', activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################\n",
    "        \n",
    "    def call(self, x, training=False):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward pass for a three-layer ConvNet. You      #\n",
    "        # should use the layer objects defined in the __init__ method.         #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        scores = self.conv1(x)\n",
    "        scores = self.conv2(scores)\n",
    "        scores = self.flatten(scores)\n",
    "        scores = self.fc(scores)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                           END OF YOUR CODE                           #\n",
    "        ########################################################################        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def test_ThreeLayerConvNet():    \n",
    "    channel_1, channel_2, num_classes = 12, 8, 10\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "    with tf.device(device):\n",
    "        x = tf.zeros((64, 3, 32, 32))\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "\n",
    "test_ThreeLayerConvNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример реализации процесса обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model_init_fn, optimizer_init_fn, num_epochs=1, is_training=False):\n",
    "    \"\"\"\n",
    "    Simple training loop for use with models defined using tf.keras. It trains\n",
    "    a model for one epoch on the CIFAR-10 training set and periodically checks\n",
    "    accuracy on the CIFAR-10 validation set.\n",
    "    \n",
    "    Inputs:\n",
    "    - model_init_fn: A function that takes no parameters; when called it\n",
    "      constructs the model we want to train: model = model_init_fn()\n",
    "    - optimizer_init_fn: A function which takes no parameters; when called it\n",
    "      constructs the Optimizer object we will use to optimize the model:\n",
    "      optimizer = optimizer_init_fn()\n",
    "    - num_epochs: The number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints progress during trainingn\n",
    "    \"\"\"    \n",
    "    with tf.device(device):\n",
    "\n",
    "        \n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "        \n",
    "        model = model_init_fn()\n",
    "        optimizer = optimizer_init_fn()\n",
    "        \n",
    "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "        val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "        val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "        \n",
    "        t = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            \n",
    "            # Reset the metrics - https://www.tensorflow.org/alpha/guide/migration_guide#new-style_metrics\n",
    "            train_loss.reset_state()\n",
    "            train_accuracy.reset_state()\n",
    "            \n",
    "            for x_np, y_np in train_dset:\n",
    "                with tf.GradientTape() as tape:\n",
    "                    \n",
    "                    # Use the model function to build the forward pass.\n",
    "                    scores = model(x_np, training=is_training)\n",
    "                    loss = loss_fn(y_np, scores)\n",
    "      \n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    \n",
    "                    # Update the metrics\n",
    "                    train_loss.update_state(loss)\n",
    "                    train_accuracy.update_state(y_np, scores)\n",
    "                    \n",
    "                    if t % print_every == 0:\n",
    "                        val_loss.reset_state()\n",
    "                        val_accuracy.reset_state()\n",
    "                        for test_x, test_y in val_dset:\n",
    "                            # During validation at end of epoch, training set to False\n",
    "                            prediction = model(test_x, training=False)\n",
    "                            t_loss = loss_fn(test_y, prediction)\n",
    "\n",
    "                            val_loss.update_state(t_loss)\n",
    "                            val_accuracy.update_state(test_y, prediction)\n",
    "                        \n",
    "                        template = 'Iteration {}, Epoch {}, Loss: {}, Accuracy: {}, Val Loss: {}, Val Accuracy: {}'\n",
    "                        print (template.format(t, epoch+1,\n",
    "                                             train_loss.result(),\n",
    "                                             train_accuracy.result()*100,\n",
    "                                             val_loss.result(),\n",
    "                                             val_accuracy.result()*100))\n",
    "                    t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.9485299587249756, Accuracy: 6.25, Val Loss: 2.9511518478393555, Val Accuracy: 12.700000762939453\n",
      "Iteration 50, Epoch 1, Loss: 2.4450135231018066, Accuracy: 24.356616973876953, Val Loss: 2.246093988418579, Val Accuracy: 31.299999237060547\n",
      "Iteration 100, Epoch 1, Loss: 2.2738003730773926, Accuracy: 28.511756896972656, Val Loss: 1.9143033027648926, Val Accuracy: 37.5\n",
      "Iteration 150, Epoch 1, Loss: 2.1631040573120117, Accuracy: 30.691225051879883, Val Loss: 1.8723206520080566, Val Accuracy: 39.39999771118164\n",
      "Iteration 200, Epoch 1, Loss: 2.093363046646118, Accuracy: 32.4238166809082, Val Loss: 1.842711329460144, Val Accuracy: 40.20000076293945\n",
      "Iteration 250, Epoch 1, Loss: 2.0527267456054688, Accuracy: 33.291831970214844, Val Loss: 1.8414257764816284, Val Accuracy: 38.29999923706055\n",
      "Iteration 300, Epoch 1, Loss: 2.013272762298584, Accuracy: 34.156978607177734, Val Loss: 1.9414770603179932, Val Accuracy: 36.099998474121094\n",
      "Iteration 350, Epoch 1, Loss: 1.9795148372650146, Accuracy: 34.99376678466797, Val Loss: 1.7523690462112427, Val Accuracy: 40.79999923706055\n",
      "Iteration 400, Epoch 1, Loss: 1.9420928955078125, Accuracy: 36.04270553588867, Val Loss: 1.7149672508239746, Val Accuracy: 42.89999771118164\n",
      "Iteration 450, Epoch 1, Loss: 1.9172639846801758, Accuracy: 36.60268783569336, Val Loss: 1.7083839178085327, Val Accuracy: 42.39999771118164\n",
      "Iteration 500, Epoch 1, Loss: 1.8961050510406494, Accuracy: 37.13510513305664, Val Loss: 1.6649409532546997, Val Accuracy: 42.29999923706055\n",
      "Iteration 550, Epoch 1, Loss: 1.878146767616272, Accuracy: 37.678653717041016, Val Loss: 1.713632583618164, Val Accuracy: 43.0\n",
      "Iteration 600, Epoch 1, Loss: 1.8634504079818726, Accuracy: 38.06936264038086, Val Loss: 1.6805086135864258, Val Accuracy: 42.099998474121094\n",
      "Iteration 650, Epoch 1, Loss: 1.8477944135665894, Accuracy: 38.450462341308594, Val Loss: 1.692600131034851, Val Accuracy: 43.099998474121094\n",
      "Iteration 700, Epoch 1, Loss: 1.8366568088531494, Accuracy: 38.76827621459961, Val Loss: 1.6525911092758179, Val Accuracy: 42.099998474121094\n",
      "Iteration 750, Epoch 1, Loss: 1.8242899179458618, Accuracy: 39.03337097167969, Val Loss: 1.606298804283142, Val Accuracy: 45.5\n"
     ]
    }
   ],
   "source": [
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return TwoLayerFC(hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите трехслойную CNN. В tf.keras.optimizers.SGD укажите Nesterov momentum = 0.9 . \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/optimizers/SGD\n",
    "\n",
    "Значение accuracy на валидационной выборке после 1 эпохи обучения должно быть > 50% ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.287132740020752, Accuracy: 7.8125, Val Loss: 2.294034719467163, Val Accuracy: 13.600000381469727\n",
      "Iteration 50, Epoch 1, Loss: 2.023817777633667, Accuracy: 27.971813201904297, Val Loss: 1.8539752960205078, Val Accuracy: 34.099998474121094\n",
      "Iteration 100, Epoch 1, Loss: 1.881248116493225, Accuracy: 32.82796859741211, Val Loss: 1.6602815389633179, Val Accuracy: 42.099998474121094\n",
      "Iteration 150, Epoch 1, Loss: 1.799367904663086, Accuracy: 36.092716217041016, Val Loss: 1.6150872707366943, Val Accuracy: 44.0\n",
      "Iteration 200, Epoch 1, Loss: 1.743436574935913, Accuracy: 38.24626922607422, Val Loss: 1.4907405376434326, Val Accuracy: 49.20000076293945\n",
      "Iteration 250, Epoch 1, Loss: 1.7042635679244995, Accuracy: 39.70991134643555, Val Loss: 1.4687167406082153, Val Accuracy: 49.39999771118164\n",
      "Iteration 300, Epoch 1, Loss: 1.6621670722961426, Accuracy: 41.21677780151367, Val Loss: 1.464042067527771, Val Accuracy: 48.69999694824219\n",
      "Iteration 350, Epoch 1, Loss: 1.6295042037963867, Accuracy: 42.365562438964844, Val Loss: 1.402113914489746, Val Accuracy: 49.900001525878906\n",
      "Iteration 400, Epoch 1, Loss: 1.5956909656524658, Accuracy: 43.52400207519531, Val Loss: 1.3671960830688477, Val Accuracy: 50.70000457763672\n",
      "Iteration 450, Epoch 1, Loss: 1.5709320306777954, Accuracy: 44.33203887939453, Val Loss: 1.3765510320663452, Val Accuracy: 52.20000076293945\n",
      "Iteration 500, Epoch 1, Loss: 1.5481613874435425, Accuracy: 45.072357177734375, Val Loss: 1.3266797065734863, Val Accuracy: 53.79999923706055\n",
      "Iteration 550, Epoch 1, Loss: 1.5326577425003052, Accuracy: 45.706668853759766, Val Loss: 1.338935136795044, Val Accuracy: 53.70000076293945\n",
      "Iteration 600, Epoch 1, Loss: 1.5181891918182373, Accuracy: 46.251041412353516, Val Loss: 1.3358469009399414, Val Accuracy: 53.29999923706055\n",
      "Iteration 650, Epoch 1, Loss: 1.5028355121612549, Accuracy: 46.894203186035156, Val Loss: 1.303492546081543, Val Accuracy: 53.500003814697266\n",
      "Iteration 700, Epoch 1, Loss: 1.4900763034820557, Accuracy: 47.338623046875, Val Loss: 1.2831318378448486, Val Accuracy: 55.400001525878906\n",
      "Iteration 750, Epoch 1, Loss: 1.4755278825759888, Accuracy: 47.82789611816406, Val Loss: 1.2568163871765137, Val Accuracy: 57.5\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 3e-3\n",
    "channel_1, channel_2, num_classes = 32, 16, 10\n",
    "\n",
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = ThreeLayerConvNet(channel_1, channel_2, num_classes)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Sequential API для реализации последовательных моделей.\n",
    "\n",
    "Пример для полносвязной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.149225950241089, Accuracy: 4.6875, Val Loss: 2.88926100730896, Val Accuracy: 14.0\n",
      "Iteration 50, Epoch 1, Loss: 2.364603042602539, Accuracy: 25.42892074584961, Val Loss: 2.219413995742798, Val Accuracy: 32.10000228881836\n",
      "Iteration 100, Epoch 1, Loss: 2.2400622367858887, Accuracy: 28.341585159301758, Val Loss: 1.9270519018173218, Val Accuracy: 37.099998474121094\n",
      "Iteration 150, Epoch 1, Loss: 2.142667770385742, Accuracy: 30.556705474853516, Val Loss: 1.9186222553253174, Val Accuracy: 37.400001525878906\n",
      "Iteration 200, Epoch 1, Loss: 2.081268548965454, Accuracy: 31.988494873046875, Val Loss: 1.8323907852172852, Val Accuracy: 39.5\n",
      "Iteration 250, Epoch 1, Loss: 2.0408129692077637, Accuracy: 32.9681282043457, Val Loss: 1.8321492671966553, Val Accuracy: 39.20000076293945\n",
      "Iteration 300, Epoch 1, Loss: 2.0040981769561768, Accuracy: 33.81956100463867, Val Loss: 1.8861968517303467, Val Accuracy: 39.5\n",
      "Iteration 350, Epoch 1, Loss: 1.9709477424621582, Accuracy: 34.73112487792969, Val Loss: 1.765537977218628, Val Accuracy: 42.0\n",
      "Iteration 400, Epoch 1, Loss: 1.9358503818511963, Accuracy: 35.7465705871582, Val Loss: 1.735677719116211, Val Accuracy: 41.400001525878906\n",
      "Iteration 450, Epoch 1, Loss: 1.9144854545593262, Accuracy: 36.2181282043457, Val Loss: 1.709552526473999, Val Accuracy: 41.80000305175781\n",
      "Iteration 500, Epoch 1, Loss: 1.8927994966506958, Accuracy: 36.75773620605469, Val Loss: 1.695971965789795, Val Accuracy: 43.29999923706055\n",
      "Iteration 550, Epoch 1, Loss: 1.876706600189209, Accuracy: 37.27880859375, Val Loss: 1.6914715766906738, Val Accuracy: 44.0\n",
      "Iteration 600, Epoch 1, Loss: 1.8626158237457275, Accuracy: 37.66379165649414, Val Loss: 1.693793535232544, Val Accuracy: 43.20000076293945\n",
      "Iteration 650, Epoch 1, Loss: 1.847211241722107, Accuracy: 38.0760383605957, Val Loss: 1.7123464345932007, Val Accuracy: 43.599998474121094\n",
      "Iteration 700, Epoch 1, Loss: 1.837112545967102, Accuracy: 38.30465316772461, Val Loss: 1.6527917385101318, Val Accuracy: 44.0\n",
      "Iteration 750, Epoch 1, Loss: 1.8245278596878052, Accuracy: 38.588134765625, Val Loss: 1.6061277389526367, Val Accuracy: 47.0\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    input_shape = (32, 32, 3)\n",
    "    hidden_layer_size, num_classes = 4000, 10\n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    layers = [\n",
    "        tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "        tf.keras.layers.Dense(hidden_layer_size, activation='relu',\n",
    "                              kernel_initializer=initializer),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax', \n",
    "                              kernel_initializer=initializer),\n",
    "    ]\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Альтернативный менее гибкий способ обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 22:50:21.350413: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 602112000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 77ms/step - loss: 2.0207 - sparse_categorical_accuracy: 0.3387 - val_loss: 1.8205 - val_sparse_categorical_accuracy: 0.4170\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - loss: 1.7689 - sparse_categorical_accuracy: 0.4153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7645881175994873, 0.4169999957084656]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перепишите реализацию трехслойной CNN с помощью tf.keras.Sequential API . Обучите модель двумя способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.3131260871887207, Accuracy: 14.0625, Val Loss: 2.3085272312164307, Val Accuracy: 12.700000762939453\n",
      "Iteration 50, Epoch 1, Loss: 2.314758539199829, Accuracy: 11.734067916870117, Val Loss: 2.2856502532958984, Val Accuracy: 13.40000057220459\n",
      "Iteration 100, Epoch 1, Loss: 2.302516460418701, Accuracy: 12.360767364501953, Val Loss: 2.2672672271728516, Val Accuracy: 14.800000190734863\n",
      "Iteration 150, Epoch 1, Loss: 2.2911875247955322, Accuracy: 13.110513687133789, Val Loss: 2.2497103214263916, Val Accuracy: 16.399999618530273\n",
      "Iteration 200, Epoch 1, Loss: 2.2811481952667236, Accuracy: 14.140235900878906, Val Loss: 2.233107566833496, Val Accuracy: 18.700000762939453\n",
      "Iteration 250, Epoch 1, Loss: 2.2726693153381348, Accuracy: 14.772161483764648, Val Loss: 2.218217611312866, Val Accuracy: 20.5\n",
      "Iteration 300, Epoch 1, Loss: 2.2642464637756348, Accuracy: 15.614618301391602, Val Loss: 2.2030749320983887, Val Accuracy: 22.30000114440918\n",
      "Iteration 350, Epoch 1, Loss: 2.2542171478271484, Accuracy: 16.559829711914062, Val Loss: 2.1855523586273193, Val Accuracy: 22.400001525878906\n",
      "Iteration 400, Epoch 1, Loss: 2.2442240715026855, Accuracy: 17.479738235473633, Val Loss: 2.168315887451172, Val Accuracy: 23.80000114440918\n",
      "Iteration 450, Epoch 1, Loss: 2.2362756729125977, Accuracy: 18.081348419189453, Val Loss: 2.1540770530700684, Val Accuracy: 24.799999237060547\n",
      "Iteration 500, Epoch 1, Loss: 2.2286229133605957, Accuracy: 18.72504997253418, Val Loss: 2.1393518447875977, Val Accuracy: 25.700000762939453\n",
      "Iteration 550, Epoch 1, Loss: 2.2204320430755615, Accuracy: 19.351179122924805, Val Loss: 2.124917507171631, Val Accuracy: 27.000001907348633\n",
      "Iteration 600, Epoch 1, Loss: 2.212782382965088, Accuracy: 19.977121353149414, Val Loss: 2.1112418174743652, Val Accuracy: 27.399999618530273\n",
      "Iteration 650, Epoch 1, Loss: 2.2049732208251953, Accuracy: 20.54531478881836, Val Loss: 2.096010208129883, Val Accuracy: 27.900001525878906\n",
      "Iteration 700, Epoch 1, Loss: 2.196889877319336, Accuracy: 21.068117141723633, Val Loss: 2.0810813903808594, Val Accuracy: 28.200000762939453\n",
      "Iteration 750, Epoch 1, Loss: 2.1889805793762207, Accuracy: 21.4984188079834, Val Loss: 2.067207098007202, Val Accuracy: 29.0\n"
     ]
    }
   ],
   "source": [
    "def model_init_fn():\n",
    "    model = None\n",
    "    ############################################################################\n",
    "    # TODO: Construct a three-layer ConvNet using tf.keras.Sequential.         #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        # Первый сверточный слой\n",
    "        tf.keras.layers.Conv2D(32, (5, 5), padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
    "        # Первый пулинг слой\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        # Второй сверточный слой\n",
    "        tf.keras.layers.Conv2D(64, (5, 5), padding='same', activation='relu'),\n",
    "        # Второй пулинг слой\n",
    "        tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
    "        # Разворачиваем данные перед подачей на полносвязный слой\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # Полносвязный слой с relu активацией\n",
    "        tf.keras.layers.Dense(1024, activation='relu'),\n",
    "        # Выходной слой с softmax активацией\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                            END OF YOUR CODE                              #\n",
    "    ############################################################################\n",
    "    return model\n",
    "\n",
    "learning_rate = 5e-4\n",
    "def optimizer_init_fn():\n",
    "    optimizer = None\n",
    "    ############################################################################\n",
    "    # TODO: Complete the implementation of model_fn.                           #\n",
    "    ############################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    ############################################################################\n",
    "    #                           END OF YOUR CODE                               #\n",
    "    ############################################################################\n",
    "    return optimizer\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-04 22:55:10.093034: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 602112000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m766/766\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 130ms/step - loss: 1.8597 - sparse_categorical_accuracy: 0.3334 - val_loss: 1.4548 - val_sparse_categorical_accuracy: 0.4950\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 21ms/step - loss: 1.4928 - sparse_categorical_accuracy: 0.4709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4937865734100342, 0.4674000144004822]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_init_fn()\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=[tf.keras.metrics.sparse_categorical_accuracy])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1, validation_data=(X_val, y_val))\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование Keras Functional API\n",
    "\n",
    "Для реализации более сложных архитектур сети с несколькими входами/выходами, повторным использованием слоев, \"остаточными\" связями (residual connections) необходимо явно указать входные и выходные тензоры. \n",
    "\n",
    "Ниже представлен пример для полносвязной сети. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 10)\n"
     ]
    }
   ],
   "source": [
    "def two_layer_fc_functional(input_shape, hidden_size, num_classes):  \n",
    "    initializer = tf.initializers.VarianceScaling(scale=2.0)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    flattened_inputs = tf.keras.layers.Flatten()(inputs)\n",
    "    fc1_output = tf.keras.layers.Dense(hidden_size, activation='relu',\n",
    "                                 kernel_initializer=initializer)(flattened_inputs)\n",
    "    scores = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                             kernel_initializer=initializer)(fc1_output)\n",
    "\n",
    "    # Instantiate the model given inputs and outputs.\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=scores)\n",
    "    return model\n",
    "\n",
    "def test_two_layer_fc_functional():\n",
    "    \"\"\" A small unit test to exercise the TwoLayerFC model above. \"\"\"\n",
    "    input_size, hidden_size, num_classes = 50, 42, 10\n",
    "    input_shape = (50,)\n",
    "    \n",
    "    x = tf.zeros((64, input_size))\n",
    "    model = two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "    \n",
    "    with tf.device(device):\n",
    "        scores = model(x)\n",
    "        print(scores.shape)\n",
    "        \n",
    "test_two_layer_fc_functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 3.1881117820739746, Accuracy: 9.375, Val Loss: 2.848323106765747, Val Accuracy: 12.5\n",
      "Iteration 50, Epoch 1, Loss: 2.3916869163513184, Accuracy: 25.245098114013672, Val Loss: 2.18837571144104, Val Accuracy: 32.60000228881836\n",
      "Iteration 100, Epoch 1, Loss: 2.2506513595581055, Accuracy: 28.341585159301758, Val Loss: 1.912186622619629, Val Accuracy: 37.099998474121094\n",
      "Iteration 150, Epoch 1, Loss: 2.144514799118042, Accuracy: 30.608442306518555, Val Loss: 1.9049874544143677, Val Accuracy: 37.70000076293945\n",
      "Iteration 200, Epoch 1, Loss: 2.0835964679718018, Accuracy: 32.299442291259766, Val Loss: 1.83794105052948, Val Accuracy: 39.70000076293945\n",
      "Iteration 250, Epoch 1, Loss: 2.046450614929199, Accuracy: 33.098854064941406, Val Loss: 1.8482515811920166, Val Accuracy: 37.70000076293945\n",
      "Iteration 300, Epoch 1, Loss: 2.006763458251953, Accuracy: 34.03239440917969, Val Loss: 1.8402645587921143, Val Accuracy: 38.60000228881836\n",
      "Iteration 350, Epoch 1, Loss: 1.9740687608718872, Accuracy: 34.873573303222656, Val Loss: 1.7654547691345215, Val Accuracy: 41.29999923706055\n",
      "Iteration 400, Epoch 1, Loss: 1.9389159679412842, Accuracy: 35.80112075805664, Val Loss: 1.7301534414291382, Val Accuracy: 43.099998474121094\n",
      "Iteration 450, Epoch 1, Loss: 1.9149010181427002, Accuracy: 36.311668395996094, Val Loss: 1.682364821434021, Val Accuracy: 43.20000076293945\n",
      "Iteration 500, Epoch 1, Loss: 1.8940880298614502, Accuracy: 36.78892135620117, Val Loss: 1.6502445936203003, Val Accuracy: 43.70000076293945\n",
      "Iteration 550, Epoch 1, Loss: 1.8766803741455078, Accuracy: 37.30149841308594, Val Loss: 1.6988998651504517, Val Accuracy: 42.89999771118164\n",
      "Iteration 600, Epoch 1, Loss: 1.8623398542404175, Accuracy: 37.72878646850586, Val Loss: 1.6979520320892334, Val Accuracy: 42.099998474121094\n",
      "Iteration 650, Epoch 1, Loss: 1.8465147018432617, Accuracy: 38.14084243774414, Val Loss: 1.6761590242385864, Val Accuracy: 42.89999771118164\n",
      "Iteration 700, Epoch 1, Loss: 1.8346034288406372, Accuracy: 38.438392639160156, Val Loss: 1.6470134258270264, Val Accuracy: 43.599998474121094\n",
      "Iteration 750, Epoch 1, Loss: 1.8225719928741455, Accuracy: 38.740013122558594, Val Loss: 1.6084027290344238, Val Accuracy: 45.89999771118164\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "hidden_size, num_classes = 4000, 10\n",
    "learning_rate = 1e-2\n",
    "\n",
    "def model_init_fn():\n",
    "    return two_layer_fc_functional(input_shape, hidden_size, num_classes)\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    return tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с архитектурой сверточной сети. Для вашего набора данных вам необходимо получить как минимум 70% accuracy на валидационной выборке за 10 эпох обучения. Опишите все эксперименты и сделайте выводы (без выполнения данного пункта работы приниматься не будут). \n",
    "\n",
    "Эспериментируйте с архитектурой, гиперпараметрами, функцией потерь, регуляризацией, методом оптимизации.  \n",
    "\n",
    "https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/BatchNormalization#methods https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/Dropout#methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Epoch 1, Loss: 2.3610124588012695, Accuracy: 14.0625, Val Loss: 2.3511886596679688, Val Accuracy: 12.199999809265137\n",
      "Iteration 500, Epoch 1, Loss: 1.6444170475006104, Accuracy: 40.25074768066406, Val Loss: 1.285671591758728, Val Accuracy: 54.5\n",
      "Iteration 1000, Epoch 2, Loss: 1.2148468494415283, Accuracy: 57.06781768798828, Val Loss: 1.0373276472091675, Val Accuracy: 65.9000015258789\n",
      "Iteration 1500, Epoch 2, Loss: 1.1421825885772705, Accuracy: 59.619476318359375, Val Loss: 1.0032247304916382, Val Accuracy: 65.5\n",
      "Iteration 2000, Epoch 3, Loss: 1.0070418119430542, Accuracy: 64.65885162353516, Val Loss: 0.9048417210578918, Val Accuracy: 68.19999694824219\n",
      "Iteration 2500, Epoch 4, Loss: 0.9400681853294373, Accuracy: 66.77955627441406, Val Loss: 0.8691628575325012, Val Accuracy: 69.5\n",
      "Iteration 3000, Epoch 4, Loss: 0.9139112830162048, Accuracy: 67.76093292236328, Val Loss: 0.8069267272949219, Val Accuracy: 73.0\n"
     ]
    }
   ],
   "source": [
    "class CustomConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomConvNet, self).__init__()\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        \n",
    "        # Дробавляем входной сверточный слой с функцией активации 'relu' и 16 фильтрами\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(32, 32, 3))\n",
    "        # Добавим скрытый сверточный слой с ядром 3 x 3 и функцией активации 'relu'\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')\n",
    "        # Максимальный пулинг 2 х 2\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        # Добавляем дропаут в 0.25\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.25)\n",
    "        # Добавим скрытый сверточный слой с ядром 3 x 3 и функцией активации 'relu'\n",
    "        self.conv3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        # Максимальный пулинг 2 х 2\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        # Слой для развертывания\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        # Полносвязный слой с функцией активации 'relu'\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        # Добавляем дропаут в 0.4\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.4)\n",
    "        # Выходной полносвязный слой с сигмоидой в качестве функции активации\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "    \n",
    "    def call(self, input_tensor, training=False):\n",
    "        ############################################################################\n",
    "        # TODO: Construct a model that performs well on CIFAR-10                   #\n",
    "        ############################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        if training:\n",
    "            x = self.dropout1(x, training=training)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "\n",
    "        if training:\n",
    "            x = self.dropout2(x, training=training)\n",
    "\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ############################################################################\n",
    "        #                            END OF YOUR CODE                              #\n",
    "        ############################################################################\n",
    "        return x\n",
    "\n",
    "\n",
    "print_every = 500\n",
    "num_epochs = 4\n",
    "\n",
    "model = CustomConvNet()\n",
    "\n",
    "def model_init_fn():\n",
    "    return CustomConvNet()\n",
    "\n",
    "def optimizer_init_fn():\n",
    "    learning_rate = 1e-3\n",
    "    return tf.keras.optimizers.Adam(learning_rate) \n",
    "\n",
    "train_part34(model_init_fn, optimizer_init_fn, num_epochs=num_epochs, is_training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опишите все эксперименты, результаты. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Архитектура сети состоит из сверточных слоев, максимального пулинга, droput, flatten и полносвязных слоев.\n",
    "На одинаковых настройках были протестированы различные оптимизаторы: SGD, Adam, RMSprop.\n",
    "Первый показал наихудшие результаты - за 10 эпох точность была в районе 30%.\n",
    "Последние два показали примерно одинаковые результаты, но в большинстве своем Adam был точнее.\n",
    "На входном и скрытом слоях сравнивались функции активации relu и sigmoid, а на входном слое тестировались sigmoid и softmax.\n",
    "При комбинации sigmoid + softmax + Adam получился наихудший результат - для получения необходимой точности потребовалось в районе 13 эпох.\n",
    "При комбинации relu + softmax + Adam был получен наилучший результат - 4 эпохи."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
